{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val: [0.96275 0.96015 0.95945]\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits. \n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.base import clone\n",
    "\n",
    "# Homemade Cross Validation\n",
    " \n",
    "# skfolds = StratifiedKFold(n_splits=5, random_state=42)\n",
    "# for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "#     clons_clf = clone(sgd_clf)\n",
    "#     X_train_folds = X_train[train_index]\n",
    "#     y_train_folds = y_train_5[train_index]\n",
    "    \n",
    "#     X_test_folds = X_train[test_index]\n",
    "#     y_test_fonds = y_train_5[test_index]\n",
    "    \n",
    "#     clons_clf.fit(X_train_folds, y_train_folds)\n",
    "#     predicts = clons_clf.predict(X_test_folds)\n",
    "#     n_correct = sum(predicts==y_test_fonds)\n",
    "#     print('precision:',n_correct*1.0/y_test_fonds.shape[0])\n",
    "    \n",
    "# OutofBox Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(\"cross_val:\",cross_val)\n",
    "\n",
    "# NoNoNo Estimator\n",
    "from sklearn.base import BaseEstimator\n",
    "class Never5Estimator(BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "    \n",
    "# cross_val = cross_val_score(Never5Estimator(), X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "# skewed datasets\n",
    "# print(\"cross_val:\",cross_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 0.8131890567578604\n",
      "recall score 0.7347352886921232\n",
      "f1 score 0.7719740284911328\n"
     ]
    }
   ],
   "source": [
    "# So introducing confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# instead of returning the evaluation scores, it returns the predictions made on each test fold.\n",
    "y_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision score',precision_score(y_train_5, y_pred))\n",
    "print('recall score',recall_score(y_train_5, y_pred))\n",
    "print('f1 score',f1_score(y_train_5, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19933.84578979])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Function\n",
    "some_digit = X[36000]\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-970773.27886713, -684609.76561583, -342860.15492126, ...,\n",
       "       -319605.46059484, -384250.85684058, -364169.16489187])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds): \n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\") \n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\") \n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([0, 1])\n",
    "%matplotlib inline\n",
    "# plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "# plt.show()\n",
    "\n",
    "# Precision versus recall\n",
    "def plot_precision_vs_recall(precisions, recalls): \n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b\") \n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "# plot_precision_vs_recall(precisions, recalls)\n",
    "# plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "def plot_roc_curve(fpr, tpr, label=None): \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label) \n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "# plot_roc_curve(fpr, tpr)\n",
    "# plt.show()\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(y_train_5, y_scores)\n",
    "\n",
    "# Plot Random Forrest RAC\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# forest_clf = RandomForestClassifier(random_state=42)\n",
    "# y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3, method=\"predict_proba\")\n",
    "# y_scores_forest = y_probas_forest[:, 1]\n",
    "# fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)\n",
    "\n",
    "# plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "# plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "# plt.legend(loc=\"bottom right\")\n",
    "# plt.show()\n",
    "\n",
    "# sgd_clf.fit(X_train, y_train)\n",
    "# sgd_clf.predict([some_digit])\n",
    "# some_digit_scores = sgd_clf.decision_function([some_digit]) # Multi Digit Score\n",
    "\n",
    "\n",
    "# cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "# Result: array([0.86472705, 0.83819191, 0.85567835])\n",
    "\n",
    "# simply scaling the inputs (as discussed in Chapter 2) increases accuracy above 90%\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "# cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "#Result array([0.91106779, 0.91044552, 0.90703606])\n",
    "\n",
    "\n",
    "\n",
    "# Measure Error\n",
    "# y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "# conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "# plt.show()\n",
    "\n",
    "# Focus on error\n",
    "# row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "# norm_conf_mx = conf_mx / row_sums\n",
    "# np.fill_diagonal(norm_conf_mx, 0)\n",
    "# plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "# plt.show()\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# EXTRA\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# cl_a, cl_b = 3, 5\n",
    "# X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "# X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "# X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "# X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "# plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "# plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "# plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  2219.810981988907\n",
      "Result is  [0.94421116 0.94124706 0.94014102]\n"
     ]
    }
   ],
   "source": [
    "# Multi Label\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# y_train_large = (y_train >= 7)\n",
    "# y_train_odd = (y_train % 2 == 1)\n",
    "# y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "# knn_clf = KNeighborsClassifier()\n",
    "# knn_clf.fit(X_train, y_multilabel)\n",
    "# knn_clf.predict([some_digit])\n",
    "# y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "# f1_score(y_train, y_train_knn_pred, average=\"macro\")\n",
    "\n",
    "# Exersize\n",
    "\n",
    "import time\n",
    "before = time.time()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "# scores = cross_val_score(knn_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "# Result [0.94361128 0.94379719 0.93909086]\n",
    "print('After ',time.time()-before)\n",
    "print('Result is ',scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-65525e3586fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m random_grid_search = RandomizedSearchCV(knn_clf, param_distributions=k_n_parameters_grid, \n\u001b[1;32m     10\u001b[0m                                         n_iter=n_iter_search, cv=3)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrandom_grid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mrandome_final_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_esitimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random grid search time:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# in this case we want to sample without replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         all_lists = np.all([not hasattr(v, \"rvs\")\n\u001b[0;32m--> 257\u001b[0;31m                             for v in self.param_distributions.values()])\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# weights n_neighbors\n",
    "k_n_parameters_grid = [{'weights':[1,5,10,50,100],'n_neighbors':['uniform','distance']},]\n",
    "\n",
    "start = time.time()\n",
    "n_iter_search = 20\n",
    "random_grid_search = RandomizedSearchCV(knn_clf, param_distributions=k_n_parameters_grid, \n",
    "                                        n_iter=n_iter_search, cv=3)\n",
    "random_grid_search.fit(X_train_scaled, y_train)\n",
    "randome_final_model = random_grid_search.best_esitimator_\n",
    "print('random grid search time:',time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
